{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/Introduction.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Agenda of this talk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below is a typical simplified Machine learning model development pipeline for tabular data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a typical model development pipeline there is raw data that exists (across servers/schemas etc) which is aggregated to get the exhaustive model development data or data which might be useful to solve the problem at hand .Post this the model development data is used to develop an outcome or the target variable(example:Sales,default,fraud etc) and independent variables which might be useful in predicting the target .The supervised machine learning algorithm uses the independent predictors and the target to develop a predictive entity which helps in getting an estimation for the predictive problem.\n",
    "\n",
    "**Today's talk is based on how the raw variables(specifically categorical variables) should be transformed for usage into model development for better predictive accuracy and long term maintainance** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.idre.ucla.edu/other/mult-pkg/whatstat/what-is-the-difference-between-categorical-ordinal-and-numerical-variables/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A Quick segway into model development data types\n",
    "<a id=data_types></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Model development data** : Data captured for most of the problem statments that you might be trying to solve should fall in one of the below buckets:\n",
    "\n",
    "- **Categorical variables:**A variable which does not represent a numeric entity or an entity that cannot be represented on a coordinate scale.They need to be transformed into a numeric format for usage in mathematical algorithms\n",
    " - **Ordinal variables:**variable  with inherent ranking/ordering\n",
    "   - Examples:Academic grades(A++,A,A-,..),Age Bracket(New born,Baby,Toddler..)\n",
    " - **High cardinality:**variable with unique values which are greater than 15(**My own thumb rule**)\n",
    "   - Examples: zipcodes,product IDs,Operating system version numbers,Email_domain_address\n",
    " - **Low cardinality:**variable with unique values which are less than 15(**My own thumb rule**)\n",
    "   - Examples: credit_default_status(YES/NO),customer_status(Active/inactive/attrited)\n",
    " - **Variables that you might mistake to be numeric variables:**A variable whose values are numbers but does not have an inherent ordering to them\n",
    "   - Examples : zipcodes,House-numbers,OS version numbers\n",
    "- **Numeric variables:** A variable which can be represented as a numeric entity or on a coordinate scale.\n",
    " - The values that a numeric variable might take might vary depending upon the variable type and can be contiguous,integers,binary.They can be used directly as predictors in mathemarical algorithms\n",
    "    - Examples :Distance,speed,Income,credit score,Indicator_for_having_a_pet(1/0)\n",
    "- **Alternate data types**\n",
    " - **Text**\n",
    " - **Images**\n",
    " - **Videos**\n",
    " - **Every other damn thing under the blue sky** ðŸ™„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lets pick up an extremely popular dataset from kaggle to get a feel of the variable types we just encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Titance dataset:Predict survival on the Titanic\n",
    "#(An extremly popular and a kind of Hello world dataset within competitive predictive modelling landscape)\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "df=pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the dataset we have 12 variables, within which Survived(Who survives the Titanic) is the binary outcome to be predicted.Let's classify each of the other features into one of the above variable classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One of the quick ways to identify  a variables type other than business/domain knowledge is to check the data types of variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Its also worth checking the number of unique values for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    891\n",
       "Survived         2\n",
       "Pclass           3\n",
       "Name           891\n",
       "Sex              2\n",
       "Age             88\n",
       "SibSp            7\n",
       "Parch            7\n",
       "Ticket         681\n",
       "Fare           248\n",
       "Cabin          147\n",
       "Embarked         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We observe that there are four variables which are classified as object dtype  which is a hint that they are categorical variables(Name,Sex,Cabin,Embarked).\n",
    "Further,we have two variables which have same number of unique values as number of passengers,indicating they are the primary keys.\n",
    "Based on that we can classify the 12 variables as:\n",
    "\n",
    "1.  **PassengerId :** The primary key passenger ID is a High cardinality categorical variable.Although the variable is numeric in form we are not classifying it as numeric as it cannot be used on numeric scale that is passenger ID 1 passenger ID 2 has no meaning.\n",
    "\n",
    "2. **Survived :** The outcome variable as this is a classification problem is a binary numeric variable(I am classifying it as numeric as it in already encoded as 1/ 0 if it was survived/Not_survived it would have been a low cardinality categorical variable which we would have needed to transform into numeric binary form for development of a classification algorithm\n",
    "\n",
    "3. **Pclass :** A Low cardinality categorical variable\n",
    "\n",
    "4. **Name :** A High cardinality categorical variable\n",
    "\n",
    "5. **Sex :** A Low cardinality categorical variable\n",
    "\n",
    "6. **Age :** A Numeric variable\n",
    "\n",
    "7. **SibSp :** # of siblings / spouses aboard the Titanic, A Numeric variable\n",
    "\n",
    "8. **Parch:** # of parents / children aboard the Titanic,A Numeric variable\n",
    "\n",
    "9. **Ticket:** Ticket number,A High cardinality categorical variable\n",
    "\n",
    "10. **Fare:** Passenger fare,A Numeric Variable\n",
    "\n",
    "11. **Cabin:** Cabin number,A High cardinality categorical variable\n",
    "\n",
    "12. **Embarked:** Port of Embarkation,A Low cardinality categorical variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some guidelines around choosing a categorical variables tranformation methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned when we were lookinng at typical data types we would face during a predictive development task that categorical variables in their raw form are not usable in a mathematical predictive algorithm and they need to be transformed into a numeric form.\n",
    "\n",
    "There are various methodologies to conduct the above tranformation for the categorical variables but before we look at them lets define few guidelines around what our final product should be and how we might want to evaluate the results of transformation from categorical to numeric.Below are three major questions that we would ask to evaluate any categorical variable transformation methodology we might find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **How much incremental improvement we observe in models predictive strength?**\n",
    "- **Will the categorical variable transformation methodology be  supported by the technical infrastructure in place for inference of the model in production?**\n",
    "- **How robust is the methodology against domain shift that we might observe in the data,which would eventually happen in this ever fluctuating world?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodologies for categorical variable transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A highly researched area within the Data science and machine learning community there are multiple ways to encode a categorical method.The best practices varies based upon data type,domain and compute power at disposal but  Below is a list of major variable transformation methodologies used in the Industry:\n",
    "\n",
    "- **One Hot encoding**\n",
    "- **Vanilla Count encoding**\n",
    "- **Vanilla target encoding**\n",
    "- **Vanilla Weight of evidence**\n",
    "\n",
    "\n",
    "Let's delve into each of them using the Titanic dataset that we encountered in [Section-2](#data_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one hot encoding we transform the categories within the variable into their own individual binary representation.Below example will make it clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Below is the Titanic dataset</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset is 891 with 12 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of the dataset is {} with {} columns\".format(df.shape[0],df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616162\n",
       "1    0.383838\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Survived'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The Survival rate is 38% as per the training data<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Before we proceed we will do some Hygiene transformaton on the data like removing redundant variables,imputing missing values and some other sanity changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> First lets split the data intp train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train,df_test=train_test_split(df,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Quick Basic Missing value imputation for few variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Age'].fillna(df_train['Age'].median(), inplace = True)\n",
    "df_test['Age'].fillna(df_train['Age'].median(), inplace = True)\n",
    "\n",
    "df_train['Embarked'].fillna(df_train['Embarked'].mode().iloc[0], inplace = True)\n",
    "df_test['Embarked'].fillna(df_train['Embarked'].mode().iloc[0], inplace = True)\n",
    "\n",
    "df_train['Cabin'].fillna(df_train['Cabin'].mode().iloc[0], inplace = True)\n",
    "df_test['Cabin'].fillna(df_train['Cabin'].mode().iloc[0], inplace = True)\n",
    "\n",
    "df_train['Pclass']=df_train['Pclass'].astype('object')\n",
    "df_test['Pclass']=df_test['Pclass'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Let's transform the port of embarkment of the passengers using one Hot encoding,where we will have seperate binary representation for each embarkment type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C', 'S', 'Q'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Embarked'].unique() # C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Embarked  Embarked_C  Embarked_Q  Embarked_S\n",
       "30         C           1           0           0\n",
       "10         S           0           0           1\n",
       "116        Q           0           1           0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.join(pd.get_dummies(df_train['Embarked'],prefix='Embarked'))[['Embarked','Embarked_C','Embarked_Q','Embarked_S']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actually need only n-1 categories to be binarized that is Embarked_S,Embarked_Q in itself capture if Embarked_C exists or not.Hence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Embarked  Embarked_Q  Embarked_S\n",
       "30         C           0           0\n",
       "10         S           0           1\n",
       "116        Q           1           0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.join(pd.get_dummies(df_train['Embarked'],prefix='Embarked',drop_first=True))[['Embarked','Embarked_Q','Embarked_S']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would now convert all predictive categorical variables in the dataset into One-hot encoded form and would attempt to develop a quick ML algorithm to predict the survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>First a List of all Categorical variables in the Titanice dataset which heuristically could be predictors of survival of a passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cat_predictors=list(df.drop(['PassengerId','Survived','Ticket',\"Name\",\"Age\",\"Fare\",\"SibSp\",\"Parch\"],axis=1).columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass', 'Sex', 'Cabin', 'Embarked']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cat_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The Below one liner in pandas will one hot encode all variables in Cat_predictors<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "OHE=ce.OneHotEncoder(df_train[Cat_predictors],use_cat_names=True)\n",
    "\n",
    "OHE.fit(df_train[Cat_predictors])\n",
    "\n",
    "df_train_OHE=df_train.join(OHE.transform(df_train[Cat_predictors]))\n",
    "df_test_OHE=df_test.join(OHE.transform(df_test[Cat_predictors]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to develop a quick model and check the predictive quality .For Absolute simplicity for this classification problem we will use a Logistic regression model .There would be probably lots of sighs and roll of eyes ðŸ™„ but come on folks this is a toy problem,we are not trying to beat SOTA ðŸ˜‰\n",
    "\n",
    "<b> <font color='red'> Note:There is lots of hand waving in the model development steps ignoring steps like correlations,robust missing value imputation,hyperparameter tuning and many other fine factors which might influence the scientific quality of a predictive model.We are doing that to be able to capture the flavor of categorical encoding within the stipulated time period.A model development process is a very nuanced process a combination of art and science.</font>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> For simplicity all the intermediate steps of model training have been pushed into a utils function,which we would be using heavily in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC is 0.8836239382827915,\n",
      "Test AUC is 0.8316455696202532\n",
      "Incremental improvement over random is 0.5721464465183058\n"
     ]
    }
   ],
   "source": [
    "model_and_predict(df_train_OHE,df_test_OHE,Cat_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **How much incremental improvement we observe in models predictive strength?**\n",
    "  - ~57% above random prediction\n",
    "- **Will the categorical variable transformation methodology be  supported by the technical infrastructure in place for inference of the model in production?**\n",
    "   - The transformation process is quite simple computationally but the write cost of categorical to binary can be quite high in case of high cardanilty variables.For example:In the Titanic dataset we have 147 cabin numbers ,Hence one variable got transformed into 146 different binary variable\n",
    "- **How robust is the methodology against domain shift that we might observe in the data,which would eventually happen in this ever fluctuating world?**\n",
    "   - In case there is a domain shift in a variable,we might loose information capture.Example: If we are applying the Titanic classification model to lets say another ship disaster ,lets call it Thanos and in case in Thanos the cabin numbers are similar but there are 150 cabin numbers instead of 147 the one hot encoded variables will not be able to capture the details about the other three.\n",
    "   <b> A solution to make the encoding stable with respect to a domain shift is including a catch-all binary variable which captured every other category that might pop-up in the future inference data<b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Count encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In count encoding every category within the variable is replaced with its corresponding count.The counts for each categiry is stored and used to encode variables during inference or in production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We will set up the count encoders and then fit it on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountEncoder(cols=['Pclass', 'Sex', 'Cabin', 'Embarked'],\n",
       "             combine_min_nan_groups=True, drop_invariant=False,\n",
       "             handle_missing='count', handle_unknown=None, min_group_name=None,\n",
       "             min_group_size=None, normalize=False, return_df=True, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_enc=ce.CountEncoder(cols=Cat_predictors)\n",
    "\n",
    "count_enc.fit(df_train[Cat_predictors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Let's have a look at the transformation of the Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Pclass_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>3</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>3</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>3</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>3</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>3</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pclass  Pclass_count\n",
       "30       1           175\n",
       "10       3           389\n",
       "873      3           389\n",
       "182      3           389\n",
       "876      3           389\n",
       "213      2           148\n",
       "157      3           389\n",
       "780      3           389\n",
       "572      1           175\n",
       "77       3           389"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.join(count_enc.transform(df_train[Cat_predictors]).add_suffix('_count'))[['Pclass','Pclass_count']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    389\n",
       "1    175\n",
       "2    148\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>As the results are what we want we will transform the train and test data for usage in model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_vce=df_train.join(count_enc.transform(df_train[Cat_predictors]).add_suffix('_count'))\n",
    "df_test_vce=df_test.join(count_enc.transform(df_test[Cat_predictors]).add_suffix('_count'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> This looks farely simple but there are some finer points which would come to haunt you during Inference time or during time you are productionalizing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> What happens if there is a domain shift,that is what if it is applied to a ship which might have cabin numbers that differ?Luckily we have the example simulated here in our test set.There are cabin numbers in test set which are not there in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A32',\n",
       " 'D9',\n",
       " 'B42',\n",
       " 'D7',\n",
       " 'D20',\n",
       " 'C148',\n",
       " 'A16',\n",
       " 'B73',\n",
       " 'E36',\n",
       " 'A23',\n",
       " 'A31',\n",
       " 'D45',\n",
       " 'E17',\n",
       " 'C30',\n",
       " 'E50',\n",
       " 'F4',\n",
       " 'E63',\n",
       " 'F E69']"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(df_test['Cabin'].unique())-set(df_train['Cabin'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> How are these Cabin numbers encoded in the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_vce[['Cabin','Cabin_count']].loc[df_test_vce['Cabin_count'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Cabin_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>A23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>F E69</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>A32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>A31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>B73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cabin  Cabin_count\n",
       "630    A23          NaN\n",
       "128  F E69          NaN\n",
       "185    A32          NaN\n",
       "209    A31          NaN\n",
       "520    B73          NaN"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_vce[['Cabin','Cabin_count']].loc[df_test_vce['Cabin'].isin(list(set(df_test['Cabin'].unique())-set(df_train['Cabin'].unique())))].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Yes,so Nan as the count encoder has not seen these values in the encoding data within training dataset.Now,what do we do?\n",
    "- The encoding code should have an additional handler for this as we will always observe these as the domain shifts and we move deeper into inference time period\n",
    "- There are multiple ways we can handle it,for simplicity we will impute the unknowns by -9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Cabin_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>A23</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>F E69</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>A32</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>A31</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>B73</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cabin  Cabin_count\n",
       "630    A23      -9999.0\n",
       "128  F E69      -9999.0\n",
       "185    A32      -9999.0\n",
       "209    A31      -9999.0\n",
       "520    B73      -9999.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_vce.fillna(-9999,inplace=True)\n",
    "\n",
    "df_test_vce[['Cabin','Cabin_count']].loc[df_test_vce['Cabin'].isin(list(set(df_test['Cabin'].unique())-set(df_train['Cabin'].unique())))].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> So,we have transformed the train and test into the format we wanted  using count encoding,Lets quickly develop  model so that we can look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC is 0.8657218830184525,\n",
      "Test AUC is 0.8384810126582278\n",
      "Incremental improvement over random is 0.5850681981335247\n"
     ]
    }
   ],
   "source": [
    "model_and_predict(df_train_vce,df_test_vce,Cat_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **How much incremental improvement we observe in models predictive strength?**\n",
    "  - ~58% above random prediction and better than one hot encoding.In practice in most cases you will find count encoding has bettter prediction numbers than a simple one hot encoding but there is also a higher possibility of overfitting(There are ways around it we will discuss it soon)\n",
    "- **Will the categorical variable transformation methodology be  supported by the technical infrastructure in place for inference of the model in production?**\n",
    "  - A simple process of transformation and much lower write cost and variable maintainance cost compared to one hot encoding as each variable is represented by one variables post transformation compared to OHE where each variable is replaced with close to as many categories as in the variable\n",
    "- **How robust is the methodology against domain shift that we might observe in the data,which would eventually happen in this ever fluctuating world?**\n",
    "   - We have discusssed how to handle domain shift whiel doing count encoding\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla target encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Target encoding each category within a variable is represented by the summary of target/outcome that it captures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Lets set up a target encoder and check how the results look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TargetEncoder(cols=['Pclass', 'Sex', 'Cabin', 'Embarked'], drop_invariant=False,\n",
       "              handle_missing='value', handle_unknown='value',\n",
       "              min_samples_leaf=1, return_df=True, smoothing=1.0, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target_enc=ce.TargetEncoder(cols=Cat_predictors)\n",
    "\n",
    "Target_enc.fit(df_train[Cat_predictors],df_train['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_vte=df_train.join(Target_enc.transform(df_train[Cat_predictors]).add_suffix('_target'))\n",
    "df_test_vte=df_test.join(Target_enc.transform(df_test[Cat_predictors]).add_suffix('_target'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "C    0.513889\n",
       "Q    0.367647\n",
       "S    0.328000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_vte.groupby('Embarked')['Survived'].agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Embarked_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>C</td>\n",
       "      <td>0.513889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S</td>\n",
       "      <td>0.328000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.367647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Embarked  Embarked_target\n",
       "30         C         0.513889\n",
       "10         S         0.328000\n",
       "116        Q         0.367647"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_vte[['Embarked','Embarked_target']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Here,we have replace variable sex by the mean captured by rolled up categories within the variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Target encoding within category encoders by default replaces the unknowns in the test by the base rate of outcome.Which again is a very rudimentray way of handling this.It can be handled in multiple different ways based on domain knowledge and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Cabin_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>A23</td>\n",
       "      <td>0.369382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>F E69</td>\n",
       "      <td>0.369382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>A32</td>\n",
       "      <td>0.369382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>A31</td>\n",
       "      <td>0.369382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>B73</td>\n",
       "      <td>0.369382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cabin  Cabin_target\n",
       "630    A23      0.369382\n",
       "128  F E69      0.369382\n",
       "185    A32      0.369382\n",
       "209    A31      0.369382\n",
       "520    B73      0.369382"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_vte[['Cabin','Cabin_target']].loc[df_test_vte['Cabin'].isin(list(set(df_test['Cabin'].unique())-set(df_train['Cabin'].unique())))].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC is 0.8711331475945701,\n",
      "Test AUC is 0.810379746835443\n",
      "Incremental improvement over random is 0.5319454414931801\n"
     ]
    }
   ],
   "source": [
    "model_and_predict(df_train_vte,df_test_vte,Cat_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **How much incremental improvement we observe in models predictive strength?**\n",
    "  - We observe a high overfitting when we use Target encoding.Hence,a drop in AUC compared to previous methods but it can be handled well as we will observe soon\n",
    "- **Will the categorical variable transformation methodology be  supported by the technical infrastructure in place for inference of the model in production?**\n",
    "  - A simple process of transformation and much lower write cost and variable maintainance cost compared to one hot encoding as each variable is represented by one variables post transformation compared to OHE where each variable is replaced with close to as many categories as in the variable\n",
    "- **How robust is the methodology against domain shift that we might observe in the data,which would eventually happen in this ever fluctuating world?**\n",
    "   - It has to be figured out how you want to handle the categories introduced due to domain shift,here we have handled using base rate of outcome in the training data\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Weight of evidence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight of evidence(WOE) can be defined as log to the ratio of percentage of events to percentage of non events  within the category being encoded for a variable.It will become easier to understand as we look at an example.We will pick Sex as a variable to learn more about weight of evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WOEEncoder(cols=['Embarked'], drop_invariant=False, handle_missing='value',\n",
       "           handle_unknown='value', random_state=None, randomized=False,\n",
       "           regularization=0, return_df=True, sigma=0.05, verbose=0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WOE_enc=ce.WOEEncoder(cols='Embarked',regularization=0) #regularization is zero to replicate the WOE manually\n",
    "WOE_enc.fit(df_train['Embarked'],df_train['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Embarked_WOE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>C</td>\n",
       "      <td>0.590439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S</td>\n",
       "      <td>-0.182376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Q</td>\n",
       "      <td>-0.007455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Embarked  Embarked_WOE\n",
       "30         C      0.590439\n",
       "10         S     -0.182376\n",
       "116        Q     -0.007455"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.join(WOE_enc.transform(df_train['Embarked']).add_suffix('_WOE'))[['Embarked','Embarked_WOE']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> To understand the calculations underneath let's calculate the WOE overself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_WOE(df,var,outcome):\n",
    "    overall_number_of_ones = df[outcome].sum()\n",
    "    overall_number_of_zeroes=df.shape[0]-overall_number_of_ones\n",
    "    grouped = pd.DataFrame()\n",
    "    grouped['Total'] = df.groupby(var)[outcome].agg('count')\n",
    "    grouped['number of ones'] = df.groupby(var)[outcome].agg('sum')\n",
    "    grouped['number of zeroes'] = grouped['Total'] - grouped['number of ones']\n",
    "\n",
    "    grouped['percentage of ones'] = grouped['number of ones'] / overall_number_of_ones\n",
    "    grouped['percentage of zeroes'] = grouped['number of zeroes'] / overall_number_of_zeroes\n",
    "    grouped['(% ones) > (% zeroes)'] = grouped['percentage of ones'] > grouped['percentage of zeroes']\n",
    "    grouped['WOE']=np.log(grouped['percentage of ones']/grouped['percentage of zeroes'])\n",
    "    \n",
    "    return grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>number of ones</th>\n",
       "      <th>number of zeroes</th>\n",
       "      <th>percentage of ones</th>\n",
       "      <th>percentage of zeroes</th>\n",
       "      <th>(% ones) &gt; (% zeroes)</th>\n",
       "      <th>WOE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>144</td>\n",
       "      <td>74</td>\n",
       "      <td>70</td>\n",
       "      <td>0.281369</td>\n",
       "      <td>0.155902</td>\n",
       "      <td>True</td>\n",
       "      <td>0.590439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>68</td>\n",
       "      <td>25</td>\n",
       "      <td>43</td>\n",
       "      <td>0.095057</td>\n",
       "      <td>0.095768</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.007455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>500</td>\n",
       "      <td>164</td>\n",
       "      <td>336</td>\n",
       "      <td>0.623574</td>\n",
       "      <td>0.748330</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.182376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total  number of ones  number of zeroes  percentage of ones  \\\n",
       "Embarked                                                                \n",
       "C           144              74                70            0.281369   \n",
       "Q            68              25                43            0.095057   \n",
       "S           500             164               336            0.623574   \n",
       "\n",
       "          percentage of zeroes  (% ones) > (% zeroes)       WOE  \n",
       "Embarked                                                         \n",
       "C                     0.155902                   True  0.590439  \n",
       "Q                     0.095768                  False -0.007455  \n",
       "S                     0.748330                  False -0.182376  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_WOE(df_train,'Embarked','Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> As we observe the WOE is a log of ratio of percentage of ones to percentage of zeros found under each variable level (female/male) in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Lets now calcualte the WOE for the entire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WOEEncoder(cols=['Pclass', 'Sex', 'Cabin', 'Embarked'], drop_invariant=False,\n",
       "           handle_missing='value', handle_unknown='value', random_state=None,\n",
       "           randomized=False, regularization=1.0, return_df=True, sigma=0.05,\n",
       "           verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WOE_enc=ce.WOEEncoder(cols=Cat_predictors) \n",
    "WOE_enc.fit(df_train[Cat_predictors],df_train['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_WOE=df_train.join(WOE_enc.transform(df_train[Cat_predictors]).add_suffix('_WOE'))\n",
    "df_test_WOE=df_test.join(WOE_enc.transform(df_test[Cat_predictors]).add_suffix('_WOE'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> What are we doing about new categories being introduced in the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Cabin_WOE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>A23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>F E69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>A32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>A31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>B73</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cabin  Cabin_WOE\n",
       "630    A23        0.0\n",
       "128  F E69        0.0\n",
       "185    A32        0.0\n",
       "209    A31        0.0\n",
       "520    B73        0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_WOE[['Cabin','Cabin_WOE']].loc[df_test_WOE['Cabin'].isin(list(set(df_test['Cabin'].unique())-set(df_train['Cabin'].unique())))].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We are replacing the new categories by a weight of evidence of zero,which is fair as the training data does not have any information about them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC is 0.8748930873000413,\n",
      "Test AUC is 0.820886075949367\n",
      "Incremental improvement over random is 0.5518066523091647\n"
     ]
    }
   ],
   "source": [
    "model_and_predict(df_train_WOE,df_test_WOE,Cat_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **How much incremental improvement we observe in models predictive strength?**\n",
    "  - As this method also use the target for transformation of categorical variables similar to Target encoding we observe a high overfitting (Big fall in discrimination performance when we move from train to test)\n",
    "- **Will the categorical variable transformation methodology be  supported by the technical infrastructure in place for inference of the model in production?**\n",
    "  - A simple process of transformation and much lower write cost and variable maintainance cost compared to one hot encoding as each variable is represented by one variables post transformation compared to OHE where each variable is replaced with close to as many categories as in the variable\n",
    "- **How robust is the methodology against domain shift that we might observe in the data,which would eventually happen in this ever fluctuating world?**\n",
    "   - We assigned a predictive WOE of zero that is neither it positively impacts survival nor negatively as per training data.Again,as per the domain knowledge this can be replaced by something else\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other useful methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>There are some other methods but the usage of them depends on the domain and type of variable you might be working on.If you reckon it fits your use case they are worth trying out to attemot the predictive efficiency of the  task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ordinal encoding \n",
    " - <b>When the variable is ordinal or has a hierarchy to it the levels within the variable can be represented by \n",
    "   integers(Difference between each integer can be choosen as per the heuristic difference in levels)\n",
    "- BaseN encoding\n",
    " - <b> Encode different level of categories into their BaseN representation,for example if N=1 it will be one hot encoded,if N=2 it will be binary encoded(Similar to OHE but we have a level 00)\n",
    "- Contrast coding\n",
    " - <b> Useful when you want to encode a variable with respect to the difference to the previous level.Useful mainly for ordinal varaibles,in practice if applied well can improve the predictive strength of a model\n",
    "- Jame-stein encoding\n",
    " - <b> A variance of Target encoding,while the target encoding replaces each variable level with its Target mean.This method further normalizes it using the  base rate of the population.There are weights of category mean and population mean which can be used to fine tune the encoding.<i><u> Helps in reducing overfitting \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learnt the concepts now some pragmatic workarounds for problems in the wild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/reality.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Although we have some good methods to try out to encode the categorical variables.As it is always across everything that we might want to do or learn,Excellence is in detail and the detail always boils down to how the data is in reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice there are various situations that you might encounter,few of which we have already observed at a very small scale:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validating the category encoding when the method overfits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the supervised encoding techniques(Target encoding,weight of evidence,Jame-stein encoding) will overfit the training data as the strength of encoding is highly dependent on how good a representation is the training data is to the in the wild population.For example:If in the training data while encoding gender we observe that males have lower survival rates than femals but the observations is opposite on an inference dataset.The encoding and simultanously the model will be negatively impacted.A way to resolve it is <b>cross validating the encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The encoding values would be calculated from the corresponding cross validation folds, Hence,there will be diversification of values for each category leading to less chances of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "def Target_encoder_kfold(train_data,test_data,Cat_vars,outcome,n_folds=4):\n",
    "    \"\"\"\n",
    "    Target encode all the cat/object vars in the data using \n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    \n",
    "    train_data:Pandad Dataframe,The data which is to be used the develop the model\n",
    "    test_data: Pandas Dataframe,The test data for model evaluation\n",
    "    outcome: Str,The string variable name which represents the outcome\n",
    "    n_folds:Number of folds for cross validation,default is 4\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    train_kfold_cp=The training data where each cat/obj var has been replaced by taget encode variable,suffix _target\n",
    "    test_kfold_cp=The test data where each cat/obj var has been replaced by taget encode variable,suffix _target\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    train_kfold_cp=train_data.copy()\n",
    "    test_kfold_cp=test_data.copy()\n",
    "    folds = KFold(n_splits=n_folds, shuffle=True, random_state=1001)\n",
    "    for cols in Cat_vars :\n",
    "        train_kfold_cp[cols]=train_kfold_cp[cols].astype('str')\n",
    "        test_kfold_cp[cols]=test_kfold_cp[cols].astype('str')\n",
    "        #print(cols)\n",
    "        train_enc = np.zeros((train_data.shape[0]))\n",
    "        for train_index,test_index in folds.split(train_kfold_cp):        \n",
    "\n",
    "            #print(f\"train : {train_R.iloc[train_index].shape} & test :{train_R.iloc[test_index].shape}\")\n",
    "\n",
    "            df_mean=train_kfold_cp.iloc[train_index].groupby(by=cols,as_index=False)[outcome].mean()\n",
    "\n",
    "            df_mean.columns=['ID',cols+'_target']\n",
    "\n",
    "            train_enc[test_index]=pd.merge(train_kfold_cp.iloc[test_index],df_mean,how='left',left_on=cols,right_on='ID')[cols+'_target'].to_numpy()\n",
    "\n",
    "\n",
    "            #target_enc = ce.TargetEncoder(cols=cols,handle_missing='return_nan',min_samples_leaf=0,smoothing=0)\n",
    "            #target_enc.fit(train_R.iloc[train_index][cols], train_R.iloc[train_index]['target'])\n",
    "            #print(train_R.iloc[test_index][cols].head())\n",
    "            #print(cols)\n",
    "            #train_enc[test_index]=target_enc.transform(train_R.iloc[test_index][cols]).to_numpy()\n",
    "        train_kfold_cp[cols+'_target']=train_enc\n",
    "        df_mean=train_kfold_cp.groupby(by=cols,as_index=False)[outcome].mean()\n",
    "        df_mean.columns=['ID',cols+'_target']\n",
    "        test_kfold_cp=pd.merge(test_kfold_cp,df_mean,how='left',left_on=cols,right_on='ID').drop('ID',axis=1)\n",
    "        #del train_kfold_cp[cols]\n",
    "        #del test_kfold_cp[cols]\n",
    "\n",
    "        print(f\"Done with {cols}\")\n",
    "    return train_kfold_cp,test_kfold_cp \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Pclass\n",
      "Done with Sex\n",
      "Done with Cabin\n",
      "Done with Embarked\n"
     ]
    }
   ],
   "source": [
    "df_train_kfold,df_test_kfold=Target_encoder_kfold(df_train,df_test,Cat_predictors,'Survived',n_folds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Lets have a quick look at how encoding has been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Embarked_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>C</td>\n",
       "      <td>0.473214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S</td>\n",
       "      <td>0.324607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>S</td>\n",
       "      <td>0.327177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>S</td>\n",
       "      <td>0.335150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>S</td>\n",
       "      <td>0.325269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>0.537736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>C</td>\n",
       "      <td>0.514851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.346939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>C</td>\n",
       "      <td>0.530973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.387755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Embarked  Embarked_target\n",
       "30         C         0.473214\n",
       "10         S         0.324607\n",
       "873        S         0.327177\n",
       "876        S         0.335150\n",
       "213        S         0.325269\n",
       "1          C         0.537736\n",
       "484        C         0.514851\n",
       "116        Q         0.346939\n",
       "330        Q         0.400000\n",
       "111        C         0.530973\n",
       "322        Q         0.333333\n",
       "612        Q         0.387755"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_kfold[['Embarked','Embarked_target']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "C    4\n",
       "Q    4\n",
       "S    4\n",
       "Name: Embarked_target, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_kfold.groupby('Embarked')['Embarked_target'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> As we observe,each of the categories seems to have multiple encoded values,that is there are 4 encoding(from each of the folds ) for each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u><i> That is how the training data is encoded,a quick look at the test data or the inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Embarked_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>0.328000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C</td>\n",
       "      <td>0.513889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.367647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Embarked  Embarked_target\n",
       "0         S         0.328000\n",
       "16        C         0.513889\n",
       "19        Q         0.367647"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_kfold[['Embarked','Embarked_target']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The test data is encoded using a vanilla target encoding.It solved two purpose:\n",
    "- Reduces overfitting in the wild as we have variance on trainig and test data during model development\n",
    "- A simpler inference workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Handling few edge cases:\n",
    "- For all those categories within a variable where we have only 1 observation we make it NA or Nan because we cannot estimate the target propensity of those using just 1 observation.This is done in both train and test set\n",
    "- This helps to reduce overfitting\n",
    "    \n",
    "<u> The missing values can be handled using advanced Missing value imputation techniques so that we have better estimate for their propensity.For simplicity we will right now replace them by -9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin\n",
       "A10      1\n",
       "A14      1\n",
       "A19      1\n",
       "A20      1\n",
       "A24      1\n",
       "        ..\n",
       "E77      1\n",
       "F G63    1\n",
       "F2       1\n",
       "F38      1\n",
       "T        1\n",
       "Name: Cabin, Length: 108, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_kfold.loc[df_train_kfold['Cabin_target'].isna()].groupby('Cabin')['Cabin'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_kfold.fillna(-9999, inplace = True)\n",
    "df_test_kfold.fillna(-9999, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC is 0.8656541363570927,\n",
      "Test AUC is 0.8156962025316457\n",
      "Incremental improvement over random is 0.5419956927494618\n"
     ]
    }
   ],
   "source": [
    "model_and_predict(df_train_kfold,df_test_kfold,Cat_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006560449859419076"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.8156962025316457-0.810379746835443)/0.810379746835443"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Even for this basic example we can observe if we compare the K-fold Target encoding with Vanilla encoding there has been a reduction in overfitting and hence an impovement in test AUC from 0.810379746835443 to 0.8156962025316457.The K-fold CV methodology explained above should be used to enhance any Category encoding method(Count encoding,Weight of evidence etc).In almost all cases you will always observe a reduction in overfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some final thumb rules/practioners tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Never pre-optimize<b> :The first target should always be getting a baseline model to which any enhancment should be compared.Always start with something simple and build on top of it\n",
    "- <b> There is no perfect encoding technique<b> : Different use cases might lead to different techniques proving better results.It highly depends on the domain and data\n",
    "- <b> Replacing missing with mean or median although simple is not be best way<b>: There is high amount of predictive power that is unused when you don't handle the missing in a smart way .The EDA for missing should be robut to take a call on how to handle them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='blue'> That's it! Thanks for your time.It was a pleassure.I can be found floating around the world wide web on below two platforms.\n",
    "   \n",
    "- Twitter-[@shub777](https://twitter.com/shub777)\n",
    "- Linkedin-[Shubrashankh Chatterjee](https://www.linkedin.com/in/shubrashankh-chatterjee/)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/Thanks.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
