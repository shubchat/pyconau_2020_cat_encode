{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.pinimg.com/originals/db/4f/88/db4f88f155d22599f59765e14f4c5497.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Agenda of this talk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below is a typical simplified Machine learning model development pipeline for tabular data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a typical model development pipeline there is raw data that exists (across servers/schemas etc) which is aggregated to get the exhaustive model development data or data which might be useful to solve the problem at hand .Post this the model development data is used to develop an outcome or the target variable(example:Sales,default,fraud etc) and independent variables which might be useful in predicting the target .The supervised machine learning algorithm uses the independent predictors and the target to develop a predictive entity which helps in getting an estimation for the predictive problem.\n",
    "\n",
    "**Today's talk is based on how the raw variables(specifically categorical variables) should be transformed for usage into model development for better predictive accuracy and long term maintainance** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_types'></a>\n",
    "# A quick segway into model development data types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.idre.ucla.edu/other/mult-pkg/whatstat/what-is-the-difference-between-categorical-ordinal-and-numerical-variables/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model development data** : Data captured for most of the problem statments that you might be trying to solve should fall in one of the below buckets:\n",
    "\n",
    "- **Categorical variables:**A variable which does not represent a numeric entity or an entity that cannot be represented on a coordinate scale.They need to be transformed into a numeric format for usage in mathematical algorithms\n",
    " - **Ordinal variables:**variable  with inherent ranking/ordering\n",
    "   - Examples:Academic grades(A++,A,A-,..),Age Bracket(New born,Baby,Toddler..)\n",
    " - **High cardinality:**variable with unique values which are greater than 15(**My own thumb rule**)\n",
    "   - Examples: zipcodes,product IDs,Operating system version numbers,Email_domain_address\n",
    " - **Low cardinality:**variable with unique values which are less than 15(**My own thumb rule**)\n",
    "   - Examples: credit_default_status(YES/NO),customer_status(Active/inactive/attrited)\n",
    " - **Variables that you might mistake to be numeric variables:**A variable whose values are numbers but does not have an inherent ordering to them\n",
    "   - Examples : zipcodes,House-numbers,OS version numbers\n",
    "- **Numeric variables:** A variable which can be represented as a numeric entity or on a coordinate scale.\n",
    " - The values that a numeric variable might take might vary depending upon the variable type and can be contiguous,integers,binary.They can be used directly as predictors in mathemarical algorithms\n",
    "    - Examples :Distance,speed,Income,credit score,Indicator_for_having_a_pet(1/0)\n",
    "- **Alternate data types**\n",
    " - **Text**\n",
    " - **Images**\n",
    " - **Videos**\n",
    " - **Every other damn thing under the blue sky** ðŸ™„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets pick up an extremely popular dataset from kaggle to get a feel of the variable types we just encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titance dataset:Predict survival on the Titanic\n",
    "#(An extremly popular and a kind of Hello world dataset within competitive predictive modelling landscape)\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset we have 12 variables, within which Survived(Who survives the Titanic) is the binary outcome to be predicted.Let's classify each of the other features into one of the above variable classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the quick ways to identify  a variables type other than business/domain knowledge is to check the data types of variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its also worth checking the number of unique values for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    891\n",
       "Survived         2\n",
       "Pclass           3\n",
       "Name           891\n",
       "Sex              2\n",
       "Age             88\n",
       "SibSp            7\n",
       "Parch            7\n",
       "Ticket         681\n",
       "Fare           248\n",
       "Cabin          147\n",
       "Embarked         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that there are four variables which are classified as object dtype  which is a hint that they are categorical variables(Name,Sex,Cabin,Embarked).\n",
    "Further,we have two variables which have same number of unique values as number of passengers,indicating they are the primary keys.\n",
    "Based on that we can classify the 12 variables as:\n",
    "\n",
    "1.  **PassengerId :** The primary key passenger ID is a High cardinality categorical variable.Although the variable is numeric in form we are not classifying it as numeric as it cannot be used on numeric scale that is passenger ID 1 passenger ID 2 has no meaning.\n",
    "\n",
    "2. **Survived :** The outcome variable as this is a classification problem is a binary numeric variable(I am classifying it as numeric as it in already encoded as 1/ 0 if it was survived/Not_survived it would have been a low cardinality categorical variable which we would have needed to transform into numeric binary form for development of a classification algorithm\n",
    "\n",
    "3. **Pclass :** A Low cardinality categorical variable\n",
    "\n",
    "4. **Name :** A High cardinality categorical variable\n",
    "\n",
    "5. **Sex :** A Low cardinality categorical variable\n",
    "\n",
    "6. **Age :** A Numeric variable\n",
    "\n",
    "7. **SibSp :** # of siblings / spouses aboard the Titanic, A Numeric variable\n",
    "\n",
    "8. **Parch:** # of parents / children aboard the Titanic,A Numeric variable\n",
    "\n",
    "9. **Ticket:** Ticket number,A High cardinality categorical variable\n",
    "\n",
    "10. **Fare:** Passenger fare,A Numeric Variable\n",
    "\n",
    "11. **Cabin:** Cabin number,A High cardinality categorical variable\n",
    "\n",
    "12. **Embarked:** Port of Embarkation,A Low cardinality categorical variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some guidelines around choosing a categorical variables tranformation methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned when we were lookinng at typical data types we would face during a predictive development task that categorical variables in their raw form are not usable in a mathematical predictive algorithm and they need to be transformed into a numeric form.\n",
    "\n",
    "There are various methodologies to conduct the above tranformation for the categorical variables but before we look at them lets define few guidelines around what our final product should be and how we might want to evaluate the results of transformation from categorical to numeric.Below are three major questions that we would ask to evaluate any categorical variable transformation methodology we might find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **How much incremental improvement we observe in models predictive strength?**\n",
    "- **Will the categorical variable transformation methodology be  supported by the technical infrastructure in place for inference of the model in production?**\n",
    "- **How robust is the methodology against domain shift that we might observe in the data,which would eventually happen in this ever fluctuating world?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodologies for categorical variable transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of major variable transformation methodologies used :\n",
    "\n",
    "- **One Hot encoding**\n",
    "- **Count encoding**\n",
    "- **Vanilla target encoding**\n",
    "- **K-fold Cross validated target encoding**\n",
    "- **Catboost encoding**\n",
    "\n",
    "Let's delve into each of them using the Titanic dataset that we encountered in [Section-2](#data_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one hot encoding we transform the categories within the variable into their own individual binary representation.Below example will make it clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Below is the Titanic dataset</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the dataset is 891 with 12 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of the dataset is {} with {} columns\".format(df.shape[0],df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616162\n",
       "1    0.383838\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Survived'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The Survival rate is 38% as per the training data<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform the Sex of the passengers using one Hot encoding,where we will have seperate binary representation for each gender type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male', 'female'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Sex_female  Sex_male\n",
       "0    male           0         1\n",
       "1  female           1         0\n",
       "2  female           1         0\n",
       "3  female           1         0\n",
       "4    male           0         1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.join(pd.get_dummies(df['Sex'],prefix='Sex'))[['Sex','Sex_female','Sex_male']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actually need only n-1 categories to be binarized that is Sex_male in itself captures the information if the sex is female or not.Hence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Sex_male\n",
       "0    male         1\n",
       "1  female         0\n",
       "2  female         0\n",
       "3  female         0\n",
       "4    male         1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.join(pd.get_dummies(df['Sex'],prefix='Sex',drop_first=True))[['Sex','Sex_male']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would now convert all predictive categorical variables in the dataset into One-hot encoded form and would attempt to develop a quick ML algorithm to predict the survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First a List of all Categorical variables in the Titanice dataset which heuristically could be predictors of survival of a passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cat_predictors=list(df.drop(['PassengerId','Survived','Ticket',\"Name\",\"Age\",\"Fare\",\"SibSp\",\"Parch\"],axis=1).columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass', 'Sex', 'Cabin', 'Embarked']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cat_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The Below one liner in pandas will one hot encode all variables in Cat_predictors<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OHE=pd.get_dummies(df,columns=Cat_predictors,dummy_na=True,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_OHE.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Finally,below are the columns in our mock modelling dataset to predict survival on Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Survived',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Fare',\n",
       " 'Pclass_2.0',\n",
       " 'Pclass_3.0',\n",
       " 'Pclass_nan',\n",
       " 'Sex_male',\n",
       " 'Sex_nan',\n",
       " 'Cabin_A14',\n",
       " 'Cabin_A16',\n",
       " 'Cabin_A19',\n",
       " 'Cabin_A20',\n",
       " 'Cabin_A23',\n",
       " 'Cabin_A24',\n",
       " 'Cabin_A26',\n",
       " 'Cabin_A31',\n",
       " 'Cabin_A32',\n",
       " 'Cabin_A34',\n",
       " 'Cabin_A36',\n",
       " 'Cabin_A5',\n",
       " 'Cabin_A6',\n",
       " 'Cabin_A7',\n",
       " 'Cabin_B101',\n",
       " 'Cabin_B102',\n",
       " 'Cabin_B18',\n",
       " 'Cabin_B19',\n",
       " 'Cabin_B20',\n",
       " 'Cabin_B22',\n",
       " 'Cabin_B28',\n",
       " 'Cabin_B3',\n",
       " 'Cabin_B30',\n",
       " 'Cabin_B35',\n",
       " 'Cabin_B37',\n",
       " 'Cabin_B38',\n",
       " 'Cabin_B39',\n",
       " 'Cabin_B4',\n",
       " 'Cabin_B41',\n",
       " 'Cabin_B42',\n",
       " 'Cabin_B49',\n",
       " 'Cabin_B5',\n",
       " 'Cabin_B50',\n",
       " 'Cabin_B51 B53 B55',\n",
       " 'Cabin_B57 B59 B63 B66',\n",
       " 'Cabin_B58 B60',\n",
       " 'Cabin_B69',\n",
       " 'Cabin_B71',\n",
       " 'Cabin_B73',\n",
       " 'Cabin_B77',\n",
       " 'Cabin_B78',\n",
       " 'Cabin_B79',\n",
       " 'Cabin_B80',\n",
       " 'Cabin_B82 B84',\n",
       " 'Cabin_B86',\n",
       " 'Cabin_B94',\n",
       " 'Cabin_B96 B98',\n",
       " 'Cabin_C101',\n",
       " 'Cabin_C103',\n",
       " 'Cabin_C104',\n",
       " 'Cabin_C106',\n",
       " 'Cabin_C110',\n",
       " 'Cabin_C111',\n",
       " 'Cabin_C118',\n",
       " 'Cabin_C123',\n",
       " 'Cabin_C124',\n",
       " 'Cabin_C125',\n",
       " 'Cabin_C126',\n",
       " 'Cabin_C128',\n",
       " 'Cabin_C148',\n",
       " 'Cabin_C2',\n",
       " 'Cabin_C22 C26',\n",
       " 'Cabin_C23 C25 C27',\n",
       " 'Cabin_C30',\n",
       " 'Cabin_C32',\n",
       " 'Cabin_C45',\n",
       " 'Cabin_C46',\n",
       " 'Cabin_C47',\n",
       " 'Cabin_C49',\n",
       " 'Cabin_C50',\n",
       " 'Cabin_C52',\n",
       " 'Cabin_C54',\n",
       " 'Cabin_C62 C64',\n",
       " 'Cabin_C65',\n",
       " 'Cabin_C68',\n",
       " 'Cabin_C7',\n",
       " 'Cabin_C70',\n",
       " 'Cabin_C78',\n",
       " 'Cabin_C82',\n",
       " 'Cabin_C83',\n",
       " 'Cabin_C85',\n",
       " 'Cabin_C86',\n",
       " 'Cabin_C87',\n",
       " 'Cabin_C90',\n",
       " 'Cabin_C91',\n",
       " 'Cabin_C92',\n",
       " 'Cabin_C93',\n",
       " 'Cabin_C95',\n",
       " 'Cabin_C99',\n",
       " 'Cabin_D',\n",
       " 'Cabin_D10 D12',\n",
       " 'Cabin_D11',\n",
       " 'Cabin_D15',\n",
       " 'Cabin_D17',\n",
       " 'Cabin_D19',\n",
       " 'Cabin_D20',\n",
       " 'Cabin_D21',\n",
       " 'Cabin_D26',\n",
       " 'Cabin_D28',\n",
       " 'Cabin_D30',\n",
       " 'Cabin_D33',\n",
       " 'Cabin_D35',\n",
       " 'Cabin_D36',\n",
       " 'Cabin_D37',\n",
       " 'Cabin_D45',\n",
       " 'Cabin_D46',\n",
       " 'Cabin_D47',\n",
       " 'Cabin_D48',\n",
       " 'Cabin_D49',\n",
       " 'Cabin_D50',\n",
       " 'Cabin_D56',\n",
       " 'Cabin_D6',\n",
       " 'Cabin_D7',\n",
       " 'Cabin_D9',\n",
       " 'Cabin_E10',\n",
       " 'Cabin_E101',\n",
       " 'Cabin_E12',\n",
       " 'Cabin_E121',\n",
       " 'Cabin_E17',\n",
       " 'Cabin_E24',\n",
       " 'Cabin_E25',\n",
       " 'Cabin_E31',\n",
       " 'Cabin_E33',\n",
       " 'Cabin_E34',\n",
       " 'Cabin_E36',\n",
       " 'Cabin_E38',\n",
       " 'Cabin_E40',\n",
       " 'Cabin_E44',\n",
       " 'Cabin_E46',\n",
       " 'Cabin_E49',\n",
       " 'Cabin_E50',\n",
       " 'Cabin_E58',\n",
       " 'Cabin_E63',\n",
       " 'Cabin_E67',\n",
       " 'Cabin_E68',\n",
       " 'Cabin_E77',\n",
       " 'Cabin_E8',\n",
       " 'Cabin_F E69',\n",
       " 'Cabin_F G63',\n",
       " 'Cabin_F G73',\n",
       " 'Cabin_F2',\n",
       " 'Cabin_F33',\n",
       " 'Cabin_F38',\n",
       " 'Cabin_F4',\n",
       " 'Cabin_G6',\n",
       " 'Cabin_T',\n",
       " 'Cabin_nan',\n",
       " 'Embarked_Q',\n",
       " 'Embarked_S',\n",
       " 'Embarked_nan']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_OHE.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age              177\n",
       "Embarked_nan       0\n",
       "Cabin_B78          0\n",
       "Cabin_C101         0\n",
       "Cabin_B96 B98      0\n",
       "                ... \n",
       "Cabin_D20          0\n",
       "Cabin_D19          0\n",
       "Cabin_D17          0\n",
       "Cabin_D15          0\n",
       "Survived           0\n",
       "Length: 160, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OHE.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values to be imputed in Age.We quickly do a based imputation using median age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OHE['Age'].fillna(df['Age'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test=train_test_split(df_OHE,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 160) (179, 160)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape,df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.617978\n",
       "1    0.382022\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Survived'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.620112\n",
       "1    0.379888\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Survived'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to develop a quick model and check the predictive quality .For Absolute simplicity for this classification problem we will use a Logistic regression model .There would be probably lots of sighs and roll of eyes ðŸ™„ but come on folks this is a toy problem,we are not trying to beat SOTA ðŸ˜‰\n",
    "\n",
    "<b> <font color='red'> Note:There is lots of hand waving in the model development steps ignoring steps like correlations,robust missing value imputation and many other fine factors which might influence the scientific quality of a predictive model.We are doing that to be able to capture the flavor of categorical encoding within the stipulated time period.</font>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "predictors=df_train.loc[:,df_train.columns!='Survived'].to_numpy()\n",
    "outcome=df_train['Survived'].to_numpy()\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shubyog/.local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(predictors,outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [28.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [31.,  1.,  1., ...,  0.,  1.,  0.],\n",
       "       ...,\n",
       "       [16.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [60.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [18.,  1.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[:,df_train.columns!='Survived'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
